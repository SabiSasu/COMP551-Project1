{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Visualize and Cluster the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Get merged data\n",
    "merged_data = pd.read_csv('../data/merged_data.csv')\n",
    "\n",
    "symptom_names = [s for s in merged_data.columns.values if s.startswith('symptom:')]\n",
    "region_names = merged_data['open_covid_region_code'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity of Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive\n",
    "\n",
    "hospitalization = widgets.Dropdown(\n",
    "    options=[True, False],\n",
    "    value=False,\n",
    "    description='Show hospitalizations: ',\n",
    ")\n",
    "\n",
    "symptom = widgets.Dropdown(\n",
    "    options=symptom_names,\n",
    "    value='symptom:Fever',\n",
    "    description='Symptoms: ',\n",
    ")\n",
    "\n",
    "region = widgets.Dropdown(\n",
    "    options=['All of USA'] + list(region_names),\n",
    "    value='All of USA',\n",
    "    description='Regions: ',\n",
    ")\n",
    "\n",
    "def plot_graph(region, symptom, hospitalization):\n",
    "    regions = region_names\n",
    "    alpha = 0.2\n",
    "\n",
    "    fig, symptom_plt = plt.subplots()\n",
    "    hosp_plt = symptom_plt.twinx()\n",
    "\n",
    "    # Aggregate hospital data across regions\n",
    "    hospital_data = merged_data.groupby('date').sum().filter(['hospitalized_new'])\n",
    "\n",
    "    # Adjust values if selecting individual region\n",
    "    if region != 'All of USA':\n",
    "        regions = [region]\n",
    "        alpha = 0.9\n",
    "        hospital_data = merged_data.loc[merged_data['open_covid_region_code'] == region].groupby('date').sum().filter(['hospitalized_new'])\n",
    "\n",
    "    hosp_plt.set_ylabel('New Hospitalizations', color='tab:blue')\n",
    "    hosp_plt.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Show hospitalization data only if selected\n",
    "    if hospitalization:\n",
    "        hosp_plt.plot(hospital_data.index.values, hospital_data['hospitalized_new'].values, color='tab:blue', alpha=0.8)\n",
    "\n",
    "    for index, region_name in enumerate(regions):\n",
    "\n",
    "        plot_data = merged_data.groupby('open_covid_region_code').get_group(region_name).sort_values(by=['date'])[['date', symptom]]\n",
    "\n",
    "        date_data = plot_data['date']\n",
    "        temp = plot_data[symptom]\n",
    "\n",
    "        symptom_plt.plot(date_data, temp, color='tab:red', alpha=alpha)\n",
    "\n",
    "    symptom_plt.tick_params(axis='y', labelcolor='tab:red')\n",
    "    symptom_plt.set_ylabel('Relative Search Frequency', color='tab:red')\n",
    "    symptom_plt.set_xlabel('Date')\n",
    "    fig.tight_layout()\n",
    "    plt.title(symptom[len('symptom:'):] + \" : \" + region)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "interactive(plot_graph, region=region, symptom=symptom, hospitalization=hospitalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search trends per region over time (plots used in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv('../data/interpolated_merged_data.csv')\n",
    "merged_data=merged_data.fillna(0)\n",
    "chosen_symptoms=['symptom:Cough', 'symptom:Common cold' , 'symptom:Fever', 'symptom:Pneumonia']\n",
    "\n",
    "symptoms_list=[s for s in merged_data.columns.values if s.startswith('symptom:')]\n",
    "regions = merged_data.groupby(merged_data['open_covid_region_code']).aggregate('count')\n",
    "regions = regions[merged_data]\n",
    "region_names = list(regions.index)\n",
    "\n",
    "by_state = merged_data.groupby('open_covid_region_code')\n",
    "\n",
    "date_data = by_state.get_group(region_names[0]).sort_values(by=['date'])['date']\n",
    "\n",
    "for sym_index, symptom_name in enumerate(symptoms_list):\n",
    "    colors = 'b', 'g', 'r', 'c', 'm', 'y', 'k'\n",
    "    width = 0.8\n",
    "    bottoms = np.array([0])\n",
    "    tempI=0\n",
    "    colIndex=0\n",
    "    for index, region_name in enumerate(region_names):\n",
    "\n",
    "        temp = by_state.get_group(region_name).sort_values(by=['date'])[symptom_name]\n",
    "        temp[np.isnan(temp)] = 0\n",
    "\n",
    "        #calculate median and divide the values in array by median\n",
    "        temp = np.true_divide(temp, np.median(temp))\n",
    "\n",
    "        #Replace all the region values in the symptom column by the median\n",
    "        for replaceI, tempEnum in enumerate(temp):\n",
    "            merged_data.at[tempI, symptom_name] = tempEnum\n",
    "            tempI+=1\n",
    "\n",
    "\n",
    "        if colIndex >= len(colors):\n",
    "            colIndex=0\n",
    "        if symptom_name in chosen_symptoms:\n",
    "            plt.bar(date_data, temp, width, bottom=bottoms, color=colors[colIndex])\n",
    "            bottoms = np.add(bottoms, np.array(temp))\n",
    "            colIndex+=1\n",
    "\n",
    "    if symptom_name in chosen_symptoms:\n",
    "        plt.title(symptom_name)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend(labels=region_names, title='states', loc='upper left',bbox_to_anchor=(1.05, 1), ncol=2)\n",
    "        plt.plot(figsize=(20,10))\n",
    "        plt.show()\n",
    "        break\n",
    "#save data\n",
    "merged_data.to_csv('../data/interpolated_merged_data_scaled.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (on all symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#PCA\n",
    "X = merged_data[merged_data.columns[4:len(symptom_names)+4]]\n",
    "\n",
    "# Figure out how many components (kinda useless)\n",
    "pca2 = PCA()\n",
    "pca2.fit_transform(StandardScaler().fit_transform(X))\n",
    "num_pc_components = len(pca2.explained_variance_ratio_)\n",
    "plt.tight_layout()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),100*pca2.explained_variance_ratio_)\n",
    "plt.xlabel(\"Principal Component #\")\n",
    "plt.ylabel(\"% Variance explained\")\n",
    "plt.title(\"Variance Explained vs Principal Components\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),100*np.cumsum(pca2.explained_variance_ratio_))\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),95*np.ones((num_pc_components,)),'k--')\n",
    "plt.xlabel(\"Principal Component #\")\n",
    "plt.ylabel(\"% Variance explained\")\n",
    "plt.title(\"Cumulative Variance Explained vs Principal Components\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "principalComponents = pca.fit_transform(StandardScaler().fit_transform(X))# Plot the explained variances\n",
    "#principalComponents = pca.fit(X)# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)# Save components to a DataFrame\n",
    "PCA_components = pd.DataFrame(principalComponents)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(PCA_components[0], PCA_components[1], alpha=.1, color='black')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.show()\n",
    "\n",
    "#PCA graph\n",
    "markersize=4\n",
    "pca = PCA(n_components=3)\n",
    "#pca.fit(X)\n",
    "#X_reduced = pca.transform(X)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize)\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Fit and transformed only data\")\n",
    "plt.show()\n",
    "\n",
    "#PCA graph with standardized data\n",
    "markersize=4\n",
    "pca = PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(StandardScaler().fit_transform(X))\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize)\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Standardized and scaled data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#knee rule to determine number of clusters\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "\n",
    "    # Fit model to samples\n",
    "    #model.fit(X)\n",
    "    model.fit(PCA_components.iloc[:, :3])\n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "plt.plot(ks, inertias, '-o', color='black')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()\n",
    "\n",
    "ks = range(2, 6)\n",
    "for k in ks:\n",
    "    #Clusters\n",
    "    clusterNum=k\n",
    "    #high is raw data\n",
    "    kmeans_high = KMeans(n_clusters=clusterNum, random_state=0)\n",
    "    kmeans_high.fit(X)\n",
    "    y_pred_high = kmeans_high.predict(X)\n",
    "\n",
    "    #low is reduced dimensionality data\n",
    "    kmeans_low = KMeans(n_clusters=clusterNum, random_state=0)\n",
    "    kmeans_low.fit(X_reduced)\n",
    "    y_pred_low = kmeans_low.predict(X_reduced)\n",
    "\n",
    "    # Plot 3 scatter plots -- two for high and low dimensional clustering results and one indicating the ground truth labels\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize, c=y_pred_high)\n",
    "    plt.colorbar(ticks=[0,1,2])\n",
    "    plt.clim(-0.5,2.5)\n",
    "    plt.xlabel(\"PC #1\")\n",
    "    plt.ylabel(\"PC #2\")\n",
    "    plt.title(\"Cluster labels for high-dimensional KMeans\")\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize, c=y_pred_low)\n",
    "    plt.colorbar(ticks=[0,1,2])\n",
    "    plt.clim(-0.5,2.5)\n",
    "    plt.xlabel(\"PC #1\")\n",
    "    plt.ylabel(\"PC #2\")\n",
    "    plt.title(\"Cluster labels for low-dimensional KMeans\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (on common Covid-19 symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "covid_symptoms = ['symptom:Common cold', 'symptom:Cough', 'symptom:Fever', 'symptom:Hay fever', 'symptom:Infection', 'symptom:Sore throat']\n",
    "\n",
    "X = merged_data[covid_symptoms]\n",
    "\n",
    "#Figure out how many components (kinda useless)\n",
    "pca2 = PCA()\n",
    "pca2.fit_transform(StandardScaler().fit_transform(X))\n",
    "num_pc_components = len(pca2.explained_variance_ratio_)\n",
    "plt.tight_layout()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),100*pca2.explained_variance_ratio_)\n",
    "plt.xlabel(\"Principal Component #\")\n",
    "plt.ylabel(\"% Variance explained\")\n",
    "plt.title(\"Variance Explained vs Principal Components\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),100*np.cumsum(pca2.explained_variance_ratio_))\n",
    "plt.plot(np.linspace(1,num_pc_components,num_pc_components),95*np.ones((num_pc_components,)),'k--')\n",
    "plt.xlabel(\"Principal Component #\")\n",
    "plt.ylabel(\"% Variance explained\")\n",
    "plt.title(\"Cumulative Variance Explained vs Principal Components\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pca = PCA(n_components=len(covid_symptoms))\n",
    "principalComponents = pca.fit_transform(StandardScaler().fit_transform(X))# Plot the explained variances\n",
    "#principalComponents = pca.fit(X)# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)# Save components to a DataFrame\n",
    "PCA_components = pd.DataFrame(principalComponents)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(PCA_components[0], PCA_components[1], alpha=.1, color='black')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.show()\n",
    "\n",
    "#PCA graph\n",
    "markersize=4\n",
    "pca = PCA(n_components=2)\n",
    "#pca.fit(X)\n",
    "#X_reduced = pca.transform(X)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize)\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Fit and transformed only data\")\n",
    "plt.show()\n",
    "\n",
    "#PCA graph with standardized data\n",
    "markersize=4\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(StandardScaler().fit_transform(X))\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize)\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Standardized and scaled data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#knee rule to determine number of clusters\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "\n",
    "    # Fit model to samples\n",
    "    #model.fit(X)\n",
    "    model.fit(PCA_components.iloc[:, :3])\n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "plt.plot(ks, inertias, '-o', color='black')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Clusters\n",
    "clusterNum=2\n",
    "#high is raw data\n",
    "kmeans_high = KMeans(n_clusters=clusterNum, random_state=0)\n",
    "kmeans_high.fit(X)\n",
    "y_pred_high = kmeans_high.predict(X)\n",
    "\n",
    "#low is reduced dimensionality data\n",
    "kmeans_low = KMeans(n_clusters=clusterNum, random_state=0)\n",
    "kmeans_low.fit(X_reduced)\n",
    "y_pred_low = kmeans_low.predict(X_reduced)\n",
    "\n",
    "# Plot 3 scatter plots -- two for high and low dimensional clustering results and one indicating the ground truth labels\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize, c=y_pred_high)\n",
    "plt.colorbar(ticks=[0,1,2])\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Cluster labels for high-dimensional KMeans\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], s=markersize, c=y_pred_low)\n",
    "plt.colorbar(ticks=[0,1,2])\n",
    "plt.clim(-0.5,2.5)\n",
    "plt.xlabel(\"PC #1\")\n",
    "plt.ylabel(\"PC #2\")\n",
    "plt.title(\"Cluster labels for low-dimensional KMeans\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
